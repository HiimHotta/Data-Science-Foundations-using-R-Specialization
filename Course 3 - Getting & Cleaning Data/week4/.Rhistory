table (quantile_gdp, res$Income.Group)
library (dplyr)
library (tidyverse)
con30 <- url ("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
con31 <- url ("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv")
q30 <- read.csv (con30, skip = 4) %>% as_tibble
q31 <- read.csv (con31) %>% as_tibble
q30<-select(q30,X,X.1,X.3,X.4)
names(q30)<-c("CountryCode", "Rank","Country","Total")
#q30 <- rename (q30, CountryCode = X)
q30 <- q30 %>% mutate(across(Rank, as.integer))
res <- inner_join(q30, q31, by = "CountryCode") %>%
arrange (desc (Rank))
res
?select
sum (!is.na(res))
sum (!is.na(res[,1]))
sum (!is.na(res[,2]))
sum (!is.na(res[,3]))
sum (!is.na(res[,4]))
library(swirl)
swirl()
Sys.getlocale("LC_TIME")
Sys.setlocale("LC_TIME", "en_US.UTF-8")
library(lubridate)
library(swirl)
swirl()
help(package = lubridate)
today()
this_day <- today()
this_day
year (this_day)
wday (this_day)
wday (this_day, label = TRUE)
this_moment <- now()
this_moment
second (this_moment)
ymd("1989-05-17")
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd ( "1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1920\1\2")
ymd("1920/1/2")
dt1
dt1_parsed <- ymd_hms(dt1)
dt1_parsed
class (dt1_parsed)
hms ("03:22:14")
library(swirl)
swirl()
dt2
ymd(dt2)
update (this_moment)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment <- update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
nyc <- now ("America/New_York")
nyc
?now
depart <- nyc + days(2)
depart
depart <- update (depart, hours = 17, minutes = 34)
depart
arrive <- update (depart, hours = 15, minutes = 50)
arrive <- depart + hours (15) + minutes (50)
?with_tz
arrive <- with_tz(arrive, "Asia/Hong_Kong")
arrive
last_time <- mdy ("June 17, 2008", tz = "Singapore")
last_time
?interval
how_long <- interval (last_time, arrive)
as.period (how_long)
stopwatch()
con <- url ("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv")
q1 <- read.csv (con)
strsplit()
?strsplit
names (q1)
strsplit(names(q1), "wgtp")
a1 <- strsplit(names(q1), "wgtp")
a1
a1[123]
con2 <- url ("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
q2 <- read.csv (con2)
names(q2)
q2["Gross.domestic.product.2012"]
head (q2)
?read.csv
con2 <- url ("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
q2 <- read.csv (con2, skip = 2)
head (q2)
con2 <- url ("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
q2 <- read.csv (con2, skip = 4)
head (q2)
con2 <- url ("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
q2 <- read.csv (con2, header = TRUE, skip = 3)
head (q2)
con2 <- url ("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
q2 <- read.csv (con2, header = TRUE, skip = 4)
head(q2)
atoi (q2[X.4])
strtoi (q2[X.4])
strtoi (q2$"X.4")
q2$X.4 <- as.numeric(gsub(",","",q2$X.4))
head(q2)
mean (q2$X.4)
mean (q2$X.4, na.rm = TRUE)
decomma (q2$X.4)
nlines (q2)
nline (q2)
count (q2)
summary (q2)
con2 <- url ("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
q2 <- read.csv (con2)
q2$X.4 <- as.numeric(gsub(",","",q2$X.4))
mean (q2$X.4, na.rm = TRUE)
head(q2)
con2 <- url ("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
q2 <- read.csv (con2, skip = 4)
q2$X.4 <- as.numeric(gsub(",","",q2$X.4))
mean (q2$X.4, na.rm = TRUE)
con2 <- url ("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
q2 <- read.csv (con2, skip = 4)
tail (q2)
q2[190]
q2[[190]]
q2[190]
q2[190,]
is.na (X.4)
is.na (q2$X.4)
q2$X.4 <- as.numeric(gsub(",","",q2$X.4))
q2$X.4 <- as.numeric(gsub(",","",q2$X.4))
q2$X.4 <- as.numeric(gsub(",","",q2$X.4))
mean (q2$X.4, na.rm = TRUE)
q2 <- read.csv (con2, skip = 4)
con2 <- url ("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
q2 <- read.csv (con2, skip = 4)
q2
sum (q2$X.4) / 190
q2$X.4 <- as.numeric(gsub(",","",q2$X.4))
sum (q2$X.4) / 190
sum (is.na (q2$X.4))
sum (!is.na (q2$X.4))
sum (q2$X.4 == !is.na (q2$X.4)))
sum (q2$X.4 == !is.na (q2$X.4))
sum (q2$X.4, na.rm = TRUE)
sum (q2$X.4, na.rm = TRUE) / 190
head (q2)
q2$X.4 <- as.integer(gsub(",","",q2$X.4))
sum (q2$X.4, na.rm = TRUE) / 190
mean (q2$X.4)
mean (q2$X.4, na.rm = TRUE)
q2$X.4 <- as.integer(gsub(',','',q2$X.4))
mean (q2$X.4, na.rm = TRUE)
sum (q2$X.4, na.rm = TRUE) / 190
con2 <- url ("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
q2 <- read.csv (con2, skip = 4, nrows = 190)
q2$X.4 <- as.integer(gsub(',','',q2$X.4))
mean (q2$X.4, na.rm = TRUE)
con3_gdp <- url ("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
q3_gdp <- read.csv (con3, skip = 4, nrows = 190)
con3_edu <- url (https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv)
q3_edu <- read.csv (con3, skip = 4, nrows = 190)
con3_gdp <- url ("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
q3_gdp <- read.csv (con3_gdp, skip = 4, nrows = 190)
con3_edu <- url (https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv)
q3_edu <- read.csv (con3_edu, nrows = 190)
con3_gdp <- url ("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
q3_gdp <- read.csv (con3_gdp, skip = 4, nrows = 190)
con3_edu <- url ("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv")
q3_edu <- read.csv (con3_edu, nrows = 190)
q3_edu
head(q3_edu)
q3_gdp
head(q3_gdp)
q30<-select(q30,X,X.1,X.3,X.4)
names(q30)<-c("CountryCode", "Rank","Country","Total")
q3_gdp<-select(q30,X,X.1,X.3,X.4)
names(q3_gdp)<-c("CountryCode", "Rank","Country","Total")
head (q3_gdp)
q3_gdp <- select(q3_gdp,X,X.1,X.3,X.4)
names(q3_gdp)<-c("CountryCode", "Rank","Country","Total")
q3_gdp <- select(q3_gdp,X,X.1,X.3,X.4)
names(q3_gdp)<-c("CountryCode", "Rank","Country","Total")
library (dplyr)
library (tidyverse)
q3_gdp <- select(q3_gdp,X,X.1,X.3,X.4)
names(q3_gdp)<-c("CountryCode", "Rank","Country","Total")
res <- inner_join(q30, q31, by = "CountryCode")
res <- inner_join(q3_gdp, q3_edu, by = "CountryCode")
head (q3_gdp)
q3_gdp <- select(q3_gdp,X,X.1,X.3,X.4)
con3_gdp <- url ("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
q3_gdp <- read.csv (con3_gdp, skip = 4, nrows = 190)
q3_gdp <- select(q3_gdp,X,X.1,X.3,X.4)
names(q3_gdp)<-c("CountryCode", "Rank","Country","Total")
res <- inner_join(q3_gdp, q3_edu, by = "CountryCode")
res
head (res)
head (res)
head (q3_edu)
q3_edu$Latest.household.survey
q3_edu$Special.Notes
grep ("Fiscal year end: June", q3_edu$Special.Notes)
grep ("Fiscal year end: June", res$Special.Notes)
res$Special.Notes
res$Special.Notes
head (res)
grep ("Fiscal year end: June", res$Special.Notes)
mergedDT <- merge(q3_edu, q3_gdp, by = 'CountryCode')
grep ("Fiscal year end: June", mergedDT$Special.Notes)
library (dplyr)
library (tidyverse)
con3_gdp <- url ("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
q3_gdp <- read.csv (con3_gdp, skip = 4, nrows = 190)
con3_edu <- url ("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv")
q3_edu <- read.csv (con3_edu)
q3_gdp <- select(q3_gdp,X,X.1,X.3,X.4)
names(q3_gdp)<-c("CountryCode", "Rank","Country","Total")
res <- inner_join(q3_gdp, q3_edu, by = "CountryCode")
library (dplyr)
library (tidyverse)
con3_gdp <- url ("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv")
q3_gdp <- read.csv (con3_gdp, skip = 4, nrows = 190)
con3_edu <- url ("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv")
q3_edu <- read.csv (con3_edu)
q3_gdp <- select(q3_gdp,X,X.1,X.3,X.4)
names(q3_gdp)<-c("CountryCode", "Rank","Country","Total")
res <- inner_join(q3_gdp, q3_edu, by = "CountryCode")
grep ("Fiscal year end: June", res$Special.Notes)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
sampleTimes
grep ("^2012", sampleTimes)
sum (grep ("^2012", sampleTimes))
count (grep ("^2012", sampleTimes))
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
res1 <- grep ("^2012", sampleTimes)
weekdays (res1)
weekdays (res1[1])
res1
res1 <- sampleTimes [grep ("^2012", sampleTimes)]
res1
weekdays (res1[1])
weekdays (res1)
res2 <- weekdays (res1)
res2 <- weekdays (res1) == "Monday"
res2
count (res2)
sum (res2)
sum (res1)
sum (grep ("^2012", sampleTimes))
length (res1)
length (res2)
View(peso_sexo)
help(write.table )
# Helped a lot: Nunno Nugroho (RPubs)
# I didn't mean to copy the answer and i checked the guide after finishing my own assignment
# because it was really weird, using 3 or 4 functions to do something simple... And I was
# correct, most answers to the assignment were resolved by 1 well designed function.
# And... The naming convention of the variables are common sense that happened way before
# i checked his answer, i am a little more reassured now that my naming choices are fine.
# (After all, english is not my native language and I'm not fluent yet)
library (dplyr)
# This one i got from a tutorial because i really think this is cool (after
# seeing the optimized way to solve some things that i made with 3 functions.
filename <- "finalProject.zip"
# Checking if archive already exists.
if (!file.exists(filename)) {
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileURL, filename, method="curl")
}
# Checking if folder exists
if (!file.exists("UCI HAR Dataset")) {
unzip(filename)
}
### 1 - Merges the training and the test sets to create one data set.
# get columns names from "root" folder
setwd ("~/UCI HAR Dataset")
features <- read.table ("features.txt", col.names = c ("n", "names"))
activity_labels <- read.table ("activity_labels.txt", col.names = c ("n", "activity"))
# get data from test folder
setwd ("test")
subject_test <- read.table ("subject_test.txt", col.names = c ("subject"))
x_test <- read.table ("X_test.txt", col.names = features$names)
y_test <- read.table ("y_test.txt", col.names = c ("activity"))
test_data <- cbind (subject_test, y_test, x_test)
rm (subject_test, y_test, x_test)
# get data from train folder
setwd ("../train")
subject_train <- read.table ("subject_train.txt", col.names = c ("subject"))
x_train <- read.table ("X_train.txt", col.names = features$names)
y_train <- read.table ("y_train.txt", col.names = c ("activity"))
train_data <- cbind (subject_train, y_train, x_train)
rm (subject_train, y_train, x_train)
# merge both datasets
merged_data <- rbind (test_data, train_data)
rm (test_data, train_data)
### 2 - Extracts only the measurements on the mean and standard deviation
###     for each measurement.
tidy_data <- merged_data %>% select (subject, activity, contains ("mean"),
contains ("std"))
### 3 - Uses descriptive activity names to name the activities in the data set
tidy_data$activity <- activity_labels [tidy_data$activity, 2]
### 4 - Appropriately labels the data set with descriptive variable names.
names (tidy_data) <- gsub ("Acc", "Accelerometer ", names (tidy_data))
names (tidy_data) <- gsub ("Gyro", "Gyroscope ", names (tidy_data))
# use of regex | " ^ " => starting position of string
names (tidy_data) <- gsub ("^t", "Time ", names (tidy_data))
names (tidy_data) <- gsub ("^f", "Frequency ", names (tidy_data))
names (tidy_data) <- gsub ("Mag", "Magnitude ", names (tidy_data))
### 5 - From the data set in step 4, creates a second, independent tidy data set
###     with the average of each variable for each activity and each subject.
tidy_data2 <- tidy_data %>% group_by (subject, activity) %>%
summarise_all (list (mean = mean))
write.table(tidy_data2, file = "tidy_data.txt", row.name = FALSE)
'
# Helped a lot: Nunno Nugroho (RPubs)
# I didnt mean to copy the answer and i checked the guide after finishing my own assignment
# because it was really weird to use 3 or 4 functions to do something simple... And I was
# correct, most answers to the assignment were resolved by 1 well designed function.
# And... The naming convention of the variables are common sense that happened way before
# i checked his answer, i am a little more reassured now that my naming choices are fine.
# (After all, english is not my native language and Im not fluent yet)'
library (dplyr)
# This one i got from a tutorial because i really think this is cool (after
# seeing the optimized way to solve some things that i made with 3 functions.
filename <- "finalProject.zip"
# Checking if archive already exists.
if (!file.exists(filename)) {
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileURL, filename, method="curl")
}
# Checking if folder exists
if (!file.exists("UCI HAR Dataset")) {
unzip(filename)
}
### 1 - Merges the training and the test sets to create one data set.
# get columns names from "root" folder
setwd ("~/UCI HAR Dataset")
features <- read.table ("features.txt", col.names = c ("n", "names"))
activity_labels <- read.table ("activity_labels.txt", col.names = c ("n", "activity"))
# get data from test folder
setwd ("test")
subject_test <- read.table ("subject_test.txt", col.names = c ("subject"))
x_test <- read.table ("X_test.txt", col.names = features$names)
y_test <- read.table ("y_test.txt", col.names = c ("activity"))
test_data <- cbind (subject_test, y_test, x_test)
rm (subject_test, y_test, x_test)
# get data from train folder
setwd ("../train")
subject_train <- read.table ("subject_train.txt", col.names = c ("subject"))
x_train <- read.table ("X_train.txt", col.names = features$names)
y_train <- read.table ("y_train.txt", col.names = c ("activity"))
train_data <- cbind (subject_train, y_train, x_train)
rm (subject_train, y_train, x_train)
# merge both datasets
merged_data <- rbind (test_data, train_data)
rm (test_data, train_data)
### 2 - Extracts only the measurements on the mean and standard deviation
###     for each measurement.
tidy_data <- merged_data %>% select (subject, activity, contains ("mean"),
contains ("std"))
### 3 - Uses descriptive activity names to name the activities in the data set
tidy_data$activity <- activity_labels [tidy_data$activity, 2]
### 4 - Appropriately labels the data set with descriptive variable names.
names (tidy_data) <- gsub ("Acc", "Accelerometer ", names (tidy_data))
names (tidy_data) <- gsub ("Gyro", "Gyroscope ", names (tidy_data))
# use of regex | " ^ " => starting position of string
names (tidy_data) <- gsub ("^t", "Time ", names (tidy_data))
names (tidy_data) <- gsub ("^f", "Frequency ", names (tidy_data))
names (tidy_data) <- gsub ("Mag", "Magnitude ", names (tidy_data))
### 5 - From the data set in step 4, creates a second, independent tidy data set
###     with the average of each variable for each activity and each subject.
tidy_data2 <- tidy_data %>% group_by (subject, activity) %>%
summarise_all (list (mean = mean))
write.table(tidy_data2, file = "tidy_data.txt", row.name = FALSE)'
)
))
ka]
]
''
setwd ("Documents/coursera/Data Science")
setwd ("Documents/coursera/"
)
getwd()
sewd ("coursera/Data Science")
setwd ("coursera/Data Science")
dir
setwd ("Couse 3 - Getting & Cleaning Datas")
setwd ("Couse 3 - Getting & Cleaning Data")
setwd ("Course 3 - Getting & Cleaning Data")
setwd ("week4")
library (dplyr)
# This one i got from a tutorial because i really think this is cool (after
# seeing the optimized way to solve some things that i made with 3 functions.
filename <- "finalProject.zip"
# Checking if archive already exists.
if (!file.exists(filename)) {
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file(fileURL, filename, method="curl")
}
# Checking if folder exists
if (!file.exists("UCI HAR Dataset")) {
unzip(filename)
}
# Checking if archive already exists.
if (!file.exists(filename)) {
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file (fileURL, filename, method="curl")
}
help ("download.file")
# Checking if archive already exists.
if (!file.exists(filename)) {
fileURL <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
download.file (fileURL, filename, method="auto")
}
# Checking if folder exists
if (!file.exists("UCI HAR Dataset")) {
unzip(filename)
}
### 1 - Merges the training and the test sets to create one data set.
# get columns names from "root" folder
setwd ("~/UCI HAR Dataset")
features <- read.table ("features.txt", col.names = c ("n", "names"))
activity_labels <- read.table ("activity_labels.txt", col.names = c ("n", "activity"))
# get data from test folder
setwd ("test")
subject_test <- read.table ("subject_test.txt", col.names = c ("subject"))
x_test <- read.table ("X_test.txt", col.names = features$names)
y_test <- read.table ("y_test.txt", col.names = c ("activity"))
test_data <- cbind (subject_test, y_test, x_test)
rm (subject_test, y_test, x_test)
# get data from train folder
setwd ("../train")
subject_train <- read.table ("subject_train.txt", col.names = c ("subject"))
x_train <- read.table ("X_train.txt", col.names = features$names)
y_train <- read.table ("y_train.txt", col.names = c ("activity"))
train_data <- cbind (subject_train, y_train, x_train)
rm (subject_train, y_train, x_train)
# merge both datasets
merged_data <- rbind (test_data, train_data)
rm (test_data, train_data)
### 2 - Extracts only the measurements on the mean and standard deviation
###     for each measurement.
tidy_data <- merged_data %>% select (subject, activity, contains ("mean"),
contains ("std"))
### 3 - Uses descriptive activity names to name the activities in the data set
tidy_data$activity <- activity_labels [tidy_data$activity, 2]
### 4 - Appropriately labels the data set with descriptive variable names.
names (tidy_data) <- gsub ("Acc", "Accelerometer ", names (tidy_data))
names (tidy_data) <- gsub ("Gyro", "Gyroscope ", names (tidy_data))
# use of regex | " ^ " => starting position of string
names (tidy_data) <- gsub ("^t", "Time ", names (tidy_data))
names (tidy_data) <- gsub ("^f", "Frequency ", names (tidy_data))
names (tidy_data) <- gsub ("Mag", "Magnitude ", names (tidy_data))
### 5 - From the data set in step 4, creates a second, independent tidy data set
###     with the average of each variable for each activity and each subject.
tidy_data2 <- tidy_data %>% group_by (subject, activity) %>%
summarise_all (list (mean = mean))
write.table(tidy_data2, file = "tidy_data.txt", row.name = FALSE)'
''
setwd ("/UCI HAR Dataset")
setwd ("UCI HAR Dataset")
features <- read.table ("features.txt", col.names = c ("n", "names"))
activity_labels <- read.table ("activity_labels.txt", col.names = c ("n", "activity"))
# get data from test folder
setwd ("test")
subject_test <- read.table ("subject_test.txt", col.names = c ("subject"))
x_test <- read.table ("X_test.txt", col.names = features$names)
y_test <- read.table ("y_test.txt", col.names = c ("activity"))
test_data <- cbind (subject_test, y_test, x_test)
rm (subject_test, y_test, x_test)
setwd ("../train")
subject_train <- read.table ("subject_train.txt", col.names = c ("subject"))
x_train <- read.table ("X_train.txt", col.names = features$names)
y_train <- read.table ("y_train.txt", col.names = c ("activity"))
train_data <- cbind (subject_train, y_train, x_train)
rm (subject_train, y_train, x_train)
# merge both datasets
merged_data <- rbind (test_data, train_data)
rm (test_data, train_data)
### 2 - Extracts only the measurements on the mean and standard deviation
###     for each measurement.
tidy_data <- merged_data %>% select (subject, activity, contains ("mean"),
contains ("std"))
### 3 - Uses descriptive activity names to name the activities in the data set
tidy_data$activity <- activity_labels [tidy_data$activity, 2]
### 4 - Appropriately labels the data set with descriptive variable names.
names (tidy_data) <- gsub ("Acc", "Accelerometer ", names (tidy_data))
names (tidy_data) <- gsub ("Gyro", "Gyroscope ", names (tidy_data))
# use of regex | " ^ " => starting position of string
names (tidy_data) <- gsub ("^t", "Time ", names (tidy_data))
names (tidy_data) <- gsub ("^f", "Frequency ", names (tidy_data))
names (tidy_data) <- gsub ("Mag", "Magnitude ", names (tidy_data))
### 5 - From the data set in step 4, creates a second, independent tidy data set
###     with the average of each variable for each activity and each subject.
tidy_data2 <- tidy_data %>% group_by (subject, activity) %>%
summarise_all (list (mean = mean))
write.table(tidy_data2, file = "tidy_data.txt", row.name = FALSE)
setwd ("../..")
write.table(tidy_data2, file = "tidy_data.txt", row.name = FALSE)
